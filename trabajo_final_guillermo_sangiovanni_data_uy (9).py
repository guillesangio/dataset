# -*- coding: utf-8 -*-
"""Trabajo Final Guillermo Sangiovanni Data.UY.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14KQyatXitN4TaepYN3JqYFGnT7N0Mmr5

# ‚¨õ  TRABAJO FINAL -  Predicci√≥n del precio de celulares con Machine Learning

---

CURSO DATA.UY

Entrega: Mayo 2025

Alumno: Guillermo Sangiovanni

URL DATASET: Smartphone_sales
https://raw.githubusercontent.com/guillesangio/dataset/refs/heads/main/smartphones.csv

# ‚≠ï PROBLEMA DEL TRABAJO:

---



---

## INTRODUCCION
Vivimos en un mercado tecnol√≥gico altamente competitivo y en constante evoluci√≥n, donde los tel√©fonos celulares presentan una enorme variedad en cuanto a caracter√≠sticas t√©cnicas, marcas y precios.

Esta diversidad hace que sea cada vez m√°s dif√≠cil establecer precios adecuados de forma objetiva, tanto para vendedores como para compradores.

Adem√°s, muchas veces el consumidor no tiene certezas sobre si el precio de un celular es justo en relaci√≥n a sus caracteristicas, o si est√° pagando principalmente por la marca.

Es com√∫n encontrar dispositivos con marcas no tan reconocidas que ofrecen las mismas prestaciones que modelos mucho m√°s costosos, generando una percepci√≥n de valor muchas veces subjetiva o desalineada con las capacidades reales del producto.




---



---



A esto se suma que el mercado es altamente vol√°til: los precios fluct√∫an constantemente y dependen de m√∫ltiples factores como:



*   Marca
*   Memoria RAM
*   Memoria de almacenamiento
*   Modelo
*   Color
*   Estado de liberaci√≥n (si es libre o que funciona unicamente con una empresa)
*   Y otras caracter√≠sticas t√©cnicas o comerciales

---



---
En resumen, existe una necesidad de **objetivar** el precio de los celulares en base a sus caracter√≠sticas t√©cnicas y no s√≥lo la marca. Este proyecto abordar√° esa necesidad desarrollando un modelo que ayude a predecir precios justos, brindando tanto a vendedores como a compradores una gu√≠a basada en datos.

**Variable a predecir:** Precio final del celular en Dolares

# ‚ñ∂ ¬øQUE QUEREMOS RESOLVER?


---



---

## OBJETIVO DEL ANALISIS
El objetivo es desarrollar un modelo de regresion capaz de predecir el precio final de un celular, a partir de sus caracter√≠sticas t√©cnicas y comerciales, ayudando en este caso en particular al usuario y comprador.

De esta manera, el modelo podr√° servir como herramienta de apoyo para identificar si un smartphone est√° sobrevaluado o subvaluado en funci√≥n de sus especificaciones, atendiendo al problema planteado

- TIPO DE PROBLEMA: Aprendizaje supervisado de regresi√≥n

  (Es supervisado porque el dataset seleccionado cuenta con precio real y ademas es una regresion porque el precio es un numero continuo)

- VARIABLE OBJETIVO: Precio final del celular

  (Valor salida del modelo)

# üì∂ EXPLORACION DEL DATASET

Importacion de librerias y iniciar la carga del dataset
"""

#Tratamiento de datos
import numpy as np
import pandas as pd

#Graficos
import matplotlib.pyplot as plt
import seaborn as sns

#Modelado
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer
from sklearn.ensemble import RandomForestRegressor
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import KNNImputer

#Warnings
import warnings
warnings.filterwarnings('ignore')

url = "https://raw.githubusercontent.com/guillesangio/dataset/refs/heads/main/smartphones.csv"
df = pd.read_csv(url)

#Dataset obtenido de pagina kaggle (https://www.kaggle.com/code/refiaozturk/smartphone-market-insights-price-ram-more/notebook)

"""### üîç Vista del DATASET utilizado
A continuaci√≥n, se muestran algunas filas del dataset:

"""

df.head()

# mostrar los nombres de las columnas del dataframe
df.columns

"""El dataset utilizado contiene informaci√≥n t√©cnica y de precios sobre distintos modelos de smartphones. Las variables incluidas son, entre otras:

- Smarphone: Nombre y caracteristicas del celular

- Brand: Marca del dispositivo

- Model: Modelo espec√≠fico

- RAM: Memoria RAM (GB)

- Storage: Almacenamiento interno del celular (GB)

- Color: Color del dispositivo

- Free: Describe si el celular es libre o de compania

- Final Price: Precio final del dispositivo (USD)

Cantidad de filas y columnas del df:
"""

df.shape

"""### üîç Vista interactiva del dataset
Dado que no se cuenta con acceso Google Sheets, se utiliza la extensi√≥n "data_table" para explorar el dataset de manera interactiva dentro del mismo notebook.
Con esta opcion podemos filtrar datos y observar el dataset completo si es lo que se quiere.
"""

from google.colab import data_table
data_table.DataTable(df)

"""### ‚ÑπÔ∏è Informaci√≥n general del dataset"""

df.info() #Informaci√≥n general del dataset

"""Faltante de datos"""

df.isna().sum().sort_values()

"""‚≠ê NOTAS:

Total de filas - 1816

- En memoria RAM hay faltante de datos o nulos. 1816 totales 1333 datos (Faltante de 483 - 26%)

- En storage hay faltante de datos o nulos. 1816 totales 1791 datos (Faltante de 25 - 2.6%)

Datos categoricos: Smartphone, Brand, Model, Color y Free

Datos numericos: RAM, Storage, Final Price

### ‚ÑπÔ∏è Informaci√≥n descriptiva del dataset

Estadistica descriptiva:

# ‚úÖ Calidad de datos
"""

df.describe()

"""‚≠ê NOTAS:

Precio promedio: 492 dolares (Precios desde los 60 a los 2271 dolares)

Memoria RAM mas utilizada: 6 GB (RAM desde 1 GB a 12GB)

Memoria de almacenamiento mas utilizada: 128 GB (Almacenamiento desde los 2 GB a los 1000 GB)

Tipos de datos del df:
"""

df.dtypes

"""‚≠ê NOTAS:

Variable categoricos: Smartphone, Brand, Model,Color y Free

Variable numericos: RAM, Storage, Final Price

# üì∂ ANALISIS DE DATOS EXPLORATORIO

üü¶ Correlacion entre variables numericas
"""

correlacion = df.corr(numeric_only=True)
plt.figure(figsize=(9, 5))
sns.heatmap(correlacion, annot=True, cmap='crest')
plt.title("Matriz de correlaci√≥n entre variables num√©ricas", fontsize=14)
plt.show()

"""‚≠ê NOTAS:

Correlaciones obtenidas:

- Relacion entre RAM y Precio final = A mayor RAM mayor es el precio pero con una
correlacion de 0.69

- Relacion entre Almacenamiento (Storage) y Precio final = A mayor almacenamiento maor es el precio, esta correlacion es bastante alta, 0.70.

- Relacion entre RAM y almacenamiento = A mayor RAM, mayor es el almacenamiento, esta es una correlacion bastante fuerte de 0.79.

üü¶ Distribucion del Precio Final de los Celulares
"""

# Distribuci√≥n variable target
# Crea una figura y un eje (subplot) con un tama√±o espec√≠fico
fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))

# Dibuja un histograma de la columna 'Final Price' del DataFrame 'df',
# e incluye la curva de densidad (kde) sobre el histograma
sns.histplot(data=df, x='Final Price', kde=True, ax=ax, color=plt.cm.BuGn(0.7))

# Asigna un t√≠tulo al gr√°fico
ax.set_title("Distribuci√≥n del Precio Final de los Celulares")

# Asigna una etiqueta al eje x
ax.set_xlabel('Final Price');

# Obtenemos las columnas num√©ricas, excepto 'Final Price'
columnas_numeric = df.select_dtypes(include=['float64', 'int']).columns
columnas_numeric = columnas_numeric.drop('Final Price')

# Gr√°fico de distribuci√≥n para cada variable num√©rica
fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))
axes = axes.flat

for i, colum in enumerate(columnas_numeric):
    sns.histplot(
        data    = df,
        x       = colum,
        stat    = "count",
        kde     = True,
        color=['darkblue', 'green'][i],
        line_kws= {'linewidth': 2},
        alpha   = 0.3,
        ax      = axes[i]
    )
    axes[i].set_title(colum, fontsize=9, fontweight="bold")
    axes[i].tick_params(labelsize=7)
    axes[i].set_xlabel("")
    axes[i].set_ylabel("")

# Ajustes finales
fig.tight_layout()
plt.subplots_adjust(top=0.88)
fig.suptitle('Distribuci√≥n de las variables num√©ricas', fontsize=12, fontweight="bold");
plt.show()

"""‚úç En este grafico observamos la distribuci√≥n de precios. Se aprecia una concentraci√≥n en la gama media a baja, con algunos outliers hacia precios m√°s altos.

"""

# Definir manualmente las columnas categ√≥ricas que quer√©s mostrar
columnas_categoricas = ["Color", "Free", "Brand"]

# Configurar grilla
n_cols = 3
n_rows = 1

fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(5*n_cols, 4*n_rows))
axes = axes.flatten()

# Graficar cada variable categ√≥rica
for i, col in enumerate(columnas_categoricas):
    sns.countplot(data=df, x=col, ax=axes[i], order=df[col].value_counts().index, palette="crest")
    axes[i].set_title(f'Distribuci√≥n de {col}')
    axes[i].tick_params(axis='x', rotation=45)

plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

"""üü¶ Distribucion de Precios por la Marca del celular"""

plt.figure(figsize=(12, 6))
sns.boxplot(x="Brand", y="Final Price", data=df, order=df["Brand"].value_counts().index, hue="Brand",palette="crest")
plt.title("Distribuci√≥n de Precios por Marca")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

"""‚úç En este boxplot podemos comparar el precio de los celularas de distintas marcas. Se observan marcas con mayor dispersi√≥n y otras m√°s estables en su rango de precios.

üü¶ Distribucion de Precios por la RAM que cuenta el celular
"""

plt.figure(figsize=(12, 6))
sns.boxplot(x="RAM", y="Final Price", data=df, hue="RAM",palette="crest")
plt.title("Distribuci√≥n de Precios por RAM")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

"""‚úç Existe una ascendente general que determina que a mayor RAM, mayor es el precio promedio de los celulares.

‚úç En la categoria 0 que equivale a 6 GB de RAM encontramos una alta dispersion, por lo cual con la RAM antes mencionada encontraremos precioso muy altamente disparejos (Muy altos o muy bajos), quizas este punto determina que celulares de alta gama utilizan esa RAM y tambien aquellos celulares clasificados como gama media o baja.

üü¶ Distribucion de Precios por Almacenamiento que tiene el celular
"""

plt.figure(figsize=(12, 6))
sns.boxplot(x="Storage", y="Final Price", data=df, hue="Storage",palette="crest")
plt.title("Distribuci√≥n de Precios por Almacenamiento")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

"""üü¶ Cantidad de celulares que cuenta cada Marca el Dataset


"""

plt.figure(figsize=(14, 8))
sns.countplot(y="Brand", data=df, order=df["Brand"].value_counts().index, hue="Brand",palette="crest")
plt.title("Cantidad de Celulares por marca")
plt.show()

"""‚úç Samsung, Xiaomi y Apple son las marcas m√°s representadas en tu dataset.

‚úç Hay muchas marcas con muy pocos modelos (por debajo de 10 unidades), como Lenovo, Swissvoice o Funker.

üîé Se tendria que evaluar en un futuro si el modelo a realizar debido a la falta de datos de algunas marcas puede afectar el entrenamiento

# üì∂ ENTRENAMIENTO DE MODELOS DE REGRESION

## Metodolog√≠a y Selecci√≥n de Modelos

Se probar√°n diferentes algoritmos de regresi√≥n con el fin de predecir el precio de los dispositivos:

- **Regresi√≥n Lineal**: modelo simple que sirve como punto de partida para comparar con otros m√©todos.
- **Random Forest Regressor**: modelo m√°s complejo que puede detectar relaciones no lineales entre las variables.
Validaci√≥n del Modelo con K-Fold Cross Validation
- **Validaci√≥n del Modelo con K-Fold Cross Validation** :utilizaremos 5 folds (k=5) para asegurarnos de que cada parte del conjunto de datos act√∫e como conjunto de validaci√≥n en una iteraci√≥n distinta, reduciendo as√≠ el riesgo de sobreajuste y obteniendo una m√©trica m√°s estable.

Adem√°s de dividir los datos en train y test (70% - 30%), aplicaremos validaci√≥n cruzada con K-Fold para evaluar la robustez de nuestros modelos.

La evaluaci√≥n de estos modelos se realizar√° utilizando m√©tricas como R¬≤, MAE y RMSE.

## Imputaci√≥n de valores faltantes:

Se imputaron los valores faltantes de RAM y Storage utilizando un m√©todo de KNN-vecinos m√°s cercanos (KNN Imputer), lo que evita descartar filas y reduce el sesgo en comparaci√≥n con imputar simplemente con la media.

¬øQUE HACEMOS?
- Separamos las columnas en numericas / categoricas
- Pipeline para los datos numericos (que son los faltantes)
  
  -Se imputan los valores usando KNN
  -Se estandarizan los datos
-Se aplica OneHotEncoder
"""

# Definir columnas
columnas_numericas = ['RAM', 'Storage']
columnas_categoricas = ['Brand', 'Color']

# Pipeline para datos num√©ricos: imputaci√≥n y escalado
pipeline_numerico = Pipeline(steps=[
    ("imputer", KNNImputer(n_neighbors=5)),
    ("scaler", StandardScaler())
])
# Definir el preprocesador (imputaci√≥n + escalado para num√©rico y codificaci√≥n para categ√≥rico)
preprocesador = ColumnTransformer(
    transformers=[
        ("num", pipeline_numerico, columnas_numericas),
        ("cat", OneHotEncoder(drop="first", handle_unknown="ignore"), columnas_categoricas)
    ]
)

# Divisi√≥n train/test
X = df[columnas_numericas + columnas_categoricas]
y = df["Final Price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Definir el pipeline para Regresi√≥n Lineal usando el preprocesador definido
pipeline_rl = Pipeline(steps=[
    ("preprocesamiento", preprocesador),
    ("modelo", LinearRegression())
])

# Entrenar modelo
pipeline_rl.fit(X_train, y_train)

# Predicciones
y_pred = pipeline_rl.predict(X_test)

# Evaluaci√≥n
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)  # calcular ra√≠z cuadrada a mano
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.2f} USD")
print(f"RMSE: {rmse:.2f} USD")
print(f"R¬≤: {r2:.3f}")

# Configurar la validaci√≥n cruzada para Regresi√≥n Lineal
kf_rl = KFold(n_splits=5, shuffle=True, random_state=42)
mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)

scores_r2_rl = cross_val_score(pipeline_rl, X, y, scoring='r2', cv=kf_rl)
scores_mae_rl = cross_val_score(pipeline_rl, X, y, scoring=mae_scorer, cv=kf_rl)

print(f"R¬≤ promedio (CV=5)  : {scores_r2_rl.mean():.3f} ¬± {scores_r2_rl.std():.3f}")
print(f"MAE promedio (CV=5) : {-scores_mae_rl.mean():.2f} USD")

# Definir el pipeline de Random Forest
pipeline_randomforest = Pipeline(steps=[
    ("preprocesamiento", preprocesador),
    ("modelo", RandomForestRegressor(n_estimators=100, random_state=42))
])

# Entrenar el modelo de Random Forest
pipeline_randomforest.fit(X_train, y_train)

# Predicciones y evaluaci√≥n
y_pred_rf = pipeline_randomforest.predict(X_test)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)

print(f"MAE: {mae_rf:.2f} USD")
print(f"RMSE: {rmse_rf:.2f} USD")
print(f"R¬≤: {r2_rf:.3f}")

# Validaci√≥n cruzada para Random Forest
kf_rf = KFold(n_splits=5, shuffle=True, random_state=42)
mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)

scores_r2_rf = cross_val_score(pipeline_randomforest, X, y, scoring='r2', cv=kf_rf)
scores_mae_rf = cross_val_score(pipeline_randomforest, X, y, scoring=mae_scorer, cv=kf_rf)

print(f"R¬≤ promedio (CV=5)  : {scores_r2_rf.mean():.3f} ¬± {scores_r2_rf.std():.3f}")
print(f"MAE promedio (CV=5) : {-scores_mae_rf.mean():.2f} USD")

"""- **MAE (Mean Absolute Error)**: muestra cu√°ntos d√≥lares, en promedio, se equivoca el modelo al predecir el precio.
- **RMSE (Root Mean Squared Error)**: es parecido al MAE, pero da m√°s importancia a los errores grandes.
- **R¬≤ (Coeficiente de Determinaci√≥n)**: indica qu√© tanto del precio real puede explicar el modelo con los datos que tiene.

# üìä EVALUACION DEL ANALISIS

## ‚úÖ RESULTADOS OBTENIDOS

### Resultados en el Conjunto de Test (70/30)


---


**Regresi√≥n Lineal**	       
- MAE Test (Dolares) - 	$ 180.35

- RMSE Test (Dolares) -  $ 253.03
- R¬≤ Test - 0.618


**Random Forest**
- MAE Test (USD) -	$ 163.22

- RMSE Test (USD)	- $ 250.62
- R¬≤ Test - 0.625


### Resultados Promedio con Validaci√≥n Cruzada (K-Fold=5)


---

**Regresi√≥n Lineal**

- R¬≤ promedio (CV=5)  : 0.604 ¬± 0.031

- MAE promedio (CV=5) : $ 176.68

**Random Forest**
- R¬≤ promedio (CV=5)  : 0.621 ¬± 0.034

- MAE promedio (CV=5) : $ 155.73

## Graficos Precios Real vs Precio Predicho
"""

plt.figure(figsize=(6, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)
min_val = min(y_test.min(), y_pred.min())
max_val = max(y_test.max(), y_pred.max())
plt.plot([min_val, max_val], [min_val, max_val], 'r--')

plt.title("Regresion Lineal - Precio Real vs Precio Predicho")
plt.xlabel("Precio Real (USD)")
plt.ylabel("Precio Predicho (USD)")
plt.show()

plt.figure(figsize=(6, 6))
sns.scatterplot(x=y_test, y=y_pred_rf, alpha=0.6)
min_val_rf = min(y_test.min(), y_pred_rf.min())
max_val_rf = max(y_test.max(), y_pred_rf.max())
plt.plot([min_val_rf, max_val_rf], [min_val_rf, max_val_rf], 'r--')



plt.title("Random Forest - Precio Real vs Precio Predicho")
plt.xlabel("Precio Real (USD)")
plt.ylabel("Precio Predicho (USD)")
plt.show()

"""## üìë CONCLUSIONES FINALES


### ‚ñ∂ CONCLUSIONES TEORICAS
---



- Ambas t√©cnicas (Regresi√≥n Lineal y Random Forest) muestran un ajuste moderado, con valores de R¬≤ alrededor de 0.60‚Äì0.62. Esto significa que explican entre el 60% y el 62% de la variabilidad en el precio de los tel√©fonos.

---



- El MAE oscila entre unos 163 y 180 USD (dependiendo del m√©todo y si es CV o test final).

---



- La validaci√≥n cruzada (CV=5) como en el test final (70/30), Random Forest logra un MAE m√°s bajo (es decir, se equivoca menos en promedio) y un R¬≤ algo mayor.


---







### ‚ñ∂ CONCLUSIONES PRACTICAS


---
- Con R¬≤ cercano a 0.60‚Äì0.62, el modelo est√° capturando algo m√°s de la mitad de la variaci√≥n en el precio de los celulares, quizas la recoleccion de datos para df podria ser mas robusta en el sentido de sumarle mayor cantidad de variables ejemplo: fecha de lanzamineto, camara, bateria, algun tipo de conectividad importante como NFC o Bluethoot.


---


- Un error promedio de 163‚Äì180 USD puede ser relevante dependiendo del rango de precios. Quizas la alta variacion de precios o mismo la volatilidad de los valores tanto de RAM como de almcacenamiento quizas el modelo pueda tener errores.


---



- Quizas a partir de los resultados del MAE un resultado de error entre los 163 - 180 en celulares de alto costo sea un resultado aceptable, quizas en los celulares de menor costo esto sea muy dificil de utilizar.

# ‚úÖ An√°lisis de errores por rangos de precio

¬øQue queremos entender? Con este grafico podemos observar c√≥mo var√≠a el error del modelo dependiendo del rango de precios. Esto permite identificar si el modelo tiene dificultades particulares para predecir celulares en ciertos segmentos de precio (bajo, medio o alto).
"""

# Crear categor√≠as por rango de precios
bins = [0, 300, 600, 1000, 2500]
labels = ['Bajo (<300)', 'Medio Bajo (300-600)', 'Medio Alto (600-1000)', 'Alto (>1000)']
test_results = X_test.copy()
test_results['Precio Real'] = y_test
test_results['Predicci√≥n RF'] = y_pred_rf
test_results['Error Absoluto'] = abs(test_results['Precio Real'] - test_results['Predicci√≥n RF'])
test_results['Rango Precio'] = pd.cut(test_results['Precio Real'], bins=bins, labels=labels)

# Visualizar errores por rango de precios
plt.figure(figsize=(10,6))
sns.boxplot(x='Rango Precio', y='Error Absoluto', data=test_results)
plt.title('Distribuci√≥n del error por rangos de precios')
plt.ylabel('Error Absoluto (USD)')
plt.xlabel('Rango de Precio')
plt.show()

"""# üìÅ Prueba Final del entrenamiento para el usuario"""

import joblib

joblib.dump(pipeline_randomforest, "modelo_celulares.pkl")

import joblib
import pandas as pd

# Cargar el pipeline (modelo) desde el archivo .pkl
modelo_celulares = joblib.load("modelo_celulares.pkl")

print("Bienvenido a la predicci√≥n del precio de celulares")
print("Por favor, ingrese los siguientes datos:")

# Preguntar al usuario e ingresar datos de forma interactiva
brand = input("Marca (Ejemplo: Samsung, Apple, Realme, Motorola,Realme,Xiaomi,POCO,Alcatel,Asus,Sony,Lenovo): ")
ram = int(input("Memoria RAM (en GB): "))
storage = int(input("Almacenamiento (en GB): "))
color = input("Color (Ejemplo: Black, White, Blue,Gray, Silver, Brozen): ")

# Preparar los datos en un DataFrame con la estructura esperada
data_ejemplo = pd.DataFrame({
    "RAM": [ram],
    "Storage": [storage],
    "Brand": [brand],
    "Color": [color]
})

# Realizar la predicci√≥n
prediccion = modelo_celulares.predict(data_ejemplo)

# Imprimir el precio estimado
print(f"Precio estimado: {prediccion[0]:.2f} USD")